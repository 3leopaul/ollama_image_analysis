{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a892e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this Notebook, I will use the Ollama 3.2 vison model to analyze images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd16e069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from ollama) (2.12.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\leopa\\documents\\installedprogramsuser\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama\n",
    "import ollama # Import the Ollama library to use Ollama models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42db912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull('llama3.2-vision') # Pull the Llama 3.2 Vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926852b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a plate of lasagna with a fork on the side. The lasagna is in the shape of a square and has a thick layer of cheese on top. It is garnished with a basil leaf.\n",
      "\n",
      "The lasagna is on a white plate, and there is a fork to the left of the plate. The background is a brown surface, possibly a tablecloth or placemat. The overall atmosphere suggests a casual dining setting, perhaps for lunch or dinner.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?', #Prompt\n",
    "        'images': ['lasagna.jpg'] # Path to the image file to be analyzed\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response['message']['content']) # Prints the responde from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba6d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the text from the image in a markdown format:\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum in velit. Quisque ac diam sed mi dictum faucibus. Phasellus accumsan velit eu justo. Ut id turpis. Donec feugiat. Pellentesque interdum metus eget ipsum. In elementum, metus non fringilla accumsan, massa eros imperdiet odio, non ultrices massa risus eget quam. Maecenas semper, quam nec porta rhoncus, enim lectus euismod eros, consequat facilisis nisl diam sed felis. Fusce aliquam sapiens sed velit. Mauris at eros sit amet nisi rhoncus cursus. Integer viverra eros eu est. Suspendisse elit tellus, congue ac, tempus nec, vestibulum non, dui. Nulla justo. Nullam nec metus quis nulla varius cursus.\n",
      "\n",
      "Sed leo. Etiam eros. Sed bibendum libero a augue. Aenean gravida. Maecenas facilisis envel risus. Cras consequet placerat quam. Praesent elementum luctus risus. Etiam at metus. Nulla consequet, arcu id pharetra, duis turpis auctor elit, sed metus dolor quam mollis est. Duiis egestas henderit orci."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you transcribe the text from this screenshot in a markdown format?', #Prompt\n",
    "        'images': ['textimage.png'] # Path to the image file to be analyzed\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c92051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a medieval-style illustration of a knight in armor, holding a sword and shield, with a quote from the book \"Ivanhoe\" by Sir Walter Scott. The knight is wearing a helmet and armor, and is standing in a forested area. The quote reads, \"Oh, Durindana, my peerless blade, What victories thou and I have made!\" The image is likely an illustration from a book or other publication, and is meant to evoke a sense of adventure and heroism."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you explain the content of this image?', #Prompt\n",
    "        'images': ['roland.webp'] # Path to the image file to be analyzed\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
